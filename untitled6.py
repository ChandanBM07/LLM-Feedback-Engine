# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1I6Sq5s7hrdGlGfTfGkNGL9wx3Ac9WorV
"""

# app.py
import io
import pandas as pd
import streamlit as st

st.set_page_config(page_title="App Reviews ‚Äì Upload & Analyze", layout="wide")
st.title("üì± App Reviews ‚Äì Upload & Analyze")
st.caption("Upload Google & Apple CSVs (or one combined CSV). No hardcoded file paths. Everything runs in memory.")

# -----------------------------
# 0) Helpers
# -----------------------------
def read_csv_robust(src, mode):
    """Read CSV from upload/url/text with fallbacks; returns (df, err)."""
    tries = [
        dict(sep=None, engine="python", on_bad_lines="skip", encoding="utf-8"),
        dict(sep=",",  engine="python", on_bad_lines="skip", encoding="utf-8"),
        dict(sep=None, engine="python", on_bad_lines="skip", encoding="latin-1"),
        dict(sep=",",  engine="python", on_bad_lines="skip", encoding="latin-1"),
    ]
    last_err = ""
    for opts in tries:
        try:
            if mode == "upload":
                return pd.read_csv(src, **opts), ""
            elif mode == "url":
                return pd.read_csv(src, **opts), ""
            elif mode == "text":
                return pd.read_csv(io.StringIO(src), **opts), ""
        except Exception as e:
            last_err = str(e)
    return pd.DataFrame(), last_err

def standardize_google(df_g):
    g = df_g.rename(columns={
        "App": "App_Name",
        "Rating": "App_Rating",
        "Category": "Category",
    }).copy()
    if "Review" not in g.columns:
        g["Review"] = "No Review Available"
    g["Source"] = "Google Play Store"
    keep = ["App_Name", "App_Rating", "Review", "Category", "Source"]
    for c in keep:
        if c not in g.columns:
            g[c] = pd.NA
    return g[keep]

def standardize_apple(df_a):
    a = df_a.rename(columns={
        "App_Name": "App_Name",
        "Rating": "App_Rating",
        "Review_Text": "Review",
        "Category": "Category",
    }).copy()
    a["Source"] = "Apple App Store"
    keep = ["App_Name", "App_Rating", "Review", "Category", "Source"]
    for c in keep:
        if c not in a.columns:
            a[c] = pd.NA
    return a[keep]

def clean(df):
    out = df.drop_duplicates().copy()
    # numeric rating with impute
    out["App_Rating"] = pd.to_numeric(out["App_Rating"], errors="coerce")
    out["App_Rating"] = out.groupby("App_Name")["App_Rating"].transform(lambda x: x.fillna(x.median()))
    out["App_Rating"] = out["App_Rating"].fillna(out["App_Rating"].median())
    # fill text fields
    for c in ["App_Name","Review","Category","Source"]:
        if c in out.columns:
            out[c] = out[c].astype(str).str.strip()
    # clamp ratings
    out = out[(out["App_Rating"] >= 1.0) & (out["App_Rating"] <= 5.0)]
    return out

def quick_polarity_label(text):
    # lightweight heuristic (no heavy models)
    s = str(text).lower()
    if s in ("", "no review available", "n/a", "none", "no comment"):
        return "NEUTRAL"
    pos_words = ("love","great","excellent","amazing","awesome","good","nice","well done","perfect")
    neg_words = ("bad","crash","bug","terrible","awful","hate","worst","slow","lag","poor")
    if any(w in s for w in pos_words) and not any(w in s for w in neg_words):
        return "POSITIVE"
    if any(w in s for w in neg_words) and not any(w in s for w in pos_words):
        return "NEGATIVE"
    return "NEUTRAL"

# -----------------------------
# 1) Inputs
# -----------------------------
st.header("1) Provide Data")

tab_up, tab_url, tab_text = st.tabs(["Upload CSVs", "GitHub Raw URL (one CSV)", "Paste CSV text (one CSV)"])

df_google = df_apple = df_one = pd.DataFrame()
source_used = None
err = ""

with tab_up:
    st.write("Upload **Google** and/or **Apple** CSVs, or upload a single combined CSV that already has columns like App_Name/Review/App_Rating.")
    up_g = st.file_uploader("Google Play CSV (optional)", type=["csv"], key="g_up")
    up_a = st.file_uploader("Apple App Store CSV (optional)", type=["csv"], key="a_up")
    up_one = st.file_uploader("Single combined CSV (optional)", type=["csv"], key="one_up")

    if up_g:
        df_google, err = read_csv_robust(up_g, "upload")
        if err: st.error(f"Google CSV read error: {err}")
    if up_a:
        df_apple, err = read_csv_robust(up_a, "upload")
        if err: st.error(f"Apple CSV read error: {err}")
    if up_one:
        df_one, err = read_csv_robust(up_one, "upload")
        if err: st.error(f"Combined CSV read error: {err}")

with tab_url:
    raw_url = st.text_input("Raw CSV URL", placeholder="https://raw.githubusercontent.com/<user>/<repo>/<branch>/path/to/file.csv")
    if raw_url:
        df_one, err = read_csv_robust(raw_url, "url")
        if err: st.error(f"URL read error: {err}")

with tab_text:
    pasted = st.text_area("Paste CSV text", placeholder="App_Name,Review,App_Rating,Category,Source\nMyApp,Great app!,5,Tools,Google Play Store")
    if pasted.strip():
        df_one, err = read_csv_robust(pasted, "text")
        if err: st.error(f"Pasted CSV read error: {err}")

# Decide which path we‚Äôre using
if not df_one.empty:
    source_used = "single"
elif not df_google.empty or not df_apple.empty:
    source_used = "pair"
else:
    st.info("‚û°Ô∏è Upload or paste at least one CSV to continue.")
    st.stop()

# -----------------------------
# 2) Build combined dataframe (in memory only)
# -----------------------------
st.header("2) Combine & Clean")

if source_used == "single":
    st.write("Using **one combined CSV** you provided.")
    # Ensure canonical columns exist; if not, try to map common names
    df = df_one.copy()
    # try minimal mapping if needed
    rename_map = {}
    col_lower = {c.lower(): c for c in df.columns}
    if "app_name" not in col_lower and "app" in col_lower: rename_map[col_lower["app"]] = "App_Name"
    if "app_rating" not in col_lower and "rating" in col_lower: rename_map[col_lower["rating"]] = "App_Rating"
    if "review" not in col_lower and "review_text" in col_lower: rename_map[col_lower["review_text"]] = "Review"
    if rename_map:
        df = df.rename(columns=rename_map)
    # ensure required columns exist for cleaning
    for c in ["App_Name","App_Rating","Review","Category","Source"]:
        if c not in df.columns: df[c] = pd.NA
    combined = df[["App_Name","App_Rating","Review","Category","Source"]].copy()

elif source_used == "pair":
    parts = []
    if not df_google.empty:
        g_std = standardize_google(df_google)
        parts.append(g_std)
        st.success(f"Google rows: {len(g_std):,}")
    if not df_apple.empty:
        a_std = standardize_apple(df_apple)
        parts.append(a_std)
        st.success(f"Apple rows: {len(a_std):,}")
    if not parts:
        st.error("No valid Google or Apple CSV uploaded.")
        st.stop()
    combined = pd.concat(parts, ignore_index=True)

st.write("Preview combined (first 100 rows):")
st.dataframe(combined.head(100), use_container_width=True)

# Clean (in memory)
cleaned = clean(combined)
st.success(f"‚úÖ Cleaned rows: {len(cleaned):,}")

# -----------------------------
# 3) Lightweight analysis (in memory)
# -----------------------------
st.header("3) Analyze")

# add quick sentiment if none present
sent_cols = [c for c in cleaned.columns if str(c).lower() in ("sentiment","sentiment_label","hybrid_sentiment_label")]
if not sent_cols:
    cleaned["Sentiment_Label"] = cleaned["Review"].apply(quick_polarity_label)
    used_sent_col = "Sentiment_Label"
else:
    # normalize to one column
    used_sent_col = sent_cols[0]
    def norm_s(v):
        s = str(v).strip().lower()
        if "pos" in s: return "POSITIVE"
        if "neg" in s: return "NEGATIVE"
        if "neu" in s or s in {"0","neutral"}: return "NEUTRAL"
        return str(v)
    cleaned["Sentiment_Label"] = cleaned[used_sent_col].apply(norm_s)
    used_sent_col = "Sentiment_Label"

# filters
cfa, cfb, cfc = st.columns(3)
apps = sorted(cleaned["App_Name"].dropna().unique().tolist())
sents = sorted(cleaned["Sentiment_Label"].dropna().unique().tolist())
cats  = sorted(cleaned["Category"].dropna().unique().tolist())

pick_apps = cfa.multiselect("Filter: App(s)", apps, default=apps[: min(5, len(apps))])
pick_sents = cfb.multiselect("Filter: Sentiment(s)", sents, default=sents)
pick_cats = cfc.multiselect("Filter: Category", cats, default=cats)

kw = st.text_input("üîç Keyword contains (in Review)")

f = cleaned.copy()
if pick_apps: f = f[f["App_Name"].isin(pick_apps)]
if pick_sents: f = f[f["Sentiment_Label"].isin(pick_sents)]
if pick_cats: f = f[f["Category"].isin(pick_cats)]
if kw: f = f[f["Review"].astype(str).str.contains(kw, case=False, na=False)]

st.metric("Filtered rows", f"{len(f):,}")

# charts (Streamlit native for reliability)
st.subheader("Sentiment breakdown")
sent_counts = f["Sentiment_Label"].value_counts().rename_axis("Sentiment").reset_index(name="Count")
if not sent_counts.empty:
    st.bar_chart(sent_counts.set_index("Sentiment"))
else:
    st.info("No data to chart.")

st.subheader("Top apps by volume")
if "App_Name" in f.columns:
    top_apps = f["App_Name"].value_counts().head(10).rename_axis("App_Name").reset_index(name="Reviews")
    st.dataframe(top_apps, use_container_width=True)

st.subheader("Ratings histogram")
if "App_Rating" in f.columns and f["App_Rating"].notna().any():
    st.bar_chart(f["App_Rating"].dropna())

st.subheader("Data (filtered)")
st.dataframe(f.reset_index(drop=True), use_container_width=True)